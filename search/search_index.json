{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"reference/","title":"API Reference","text":""},{"location":"reference/#dsx.ds_utils.dsx","title":"<code>dsx</code>","text":"<p>             Bases: <code>object</code></p> <p>The dsx module (same name but not to confuse with the package name) contains a collection of wrapper functions to simplify common operations in data analytics tasks. The core module ds_utils (data science utilities) is designed to work with DataFrame in Pandas to simplify common tasks</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>@pd.api.extensions.register_dataframe_accessor(\"ds\")\nclass dsx(object):\n\"\"\"\n\t\tThe **dsx** module (same name but not to confuse with the package name) contains a collection of wrapper functions to simplify common operations in data analytics tasks.\n\t\tThe core module ds_utils (data science utilities) is designed to work with DataFrame in Pandas to simplify common tasks\n\t\"\"\"\n\tbackup_repo = {}\n\n\n\t# Constructor\n\tdef __init__(self, pandas_obj):\n\t\tself._obj = pandas_obj\n\n\n\t# region &lt;&lt; Class Variable &gt;&gt;\n'''\n\tThese are needed.\n\tAlthough class variables can be directly use in the @classmethod without defined here,\n\tbut if the variable needs to be set to default value, the variable should be 'declared' here.\n\t'''\n\tdir_project = None\n\tdir_data = None\n\tdir_temp = None\n\n\n\t# region &lt;&lt; columns operations &gt;&gt;\n\tdef cols_std(self, inplace=True, lower=False):\n\"\"\"\n\t\t\tTo standardize the names of all columns, to be compatible with iPython.\n\t\t\tThis method removes space and special characterss in the column names.\n\t\t\tAfter standardized, the column names can be used as attribute of the DataFrame (with autocomplete) in iPython\n\n\t\tParameters\n\t\t----------\n\t\tinplace: bool\n\n\t\tcamel: bool\n\n\n\t\tReturns\n\t\t-------\n\t\tpandas.core.frame.DataFrame\n\t\t\tOnly when inplace parameter is set to False\n\t\t\"\"\"\n\t\tdf_input = self._obj\n\t\tif inplace:\n\t\t\tdf = df_input\n\t\telse:\n\t\t\tdf = df_input.copy()\n\t\timport re\n\t\tpat = re.compile(r'[\\W]+')\n\t\tdf.columns = df.columns.str.replace(pat, '_')\n\t\tdf.columns = df.columns.str.strip('_')\n\t\tpat_Multi_Underscore = re.compile(r'[_]{2,}')\n\t\tdf.columns = df.columns.str.replace(pat_Multi_Underscore, '_')\n\t\tif lower == True:\n\t\t\tdf.columns = df.columns.str.lower()\n\n\t\tif inplace:\n\t\t\tdf_input = df.copy()\n\t\telse:\n\t\t\treturn df\n\n\n\tdef info(self):\n\"\"\"\n\t\tTo generate the meta-data of the DataFrame.\n\t\tMeta-data includes the following:\n\t\t- Column Names\n\t\t- Missing Count\n\t\t- Missing Percentage\n\t\t- Unique Value Count (nunique)\n\t\t- Unique Value Percentage\n\n\t\tReturns\n\t\t-------\n\t\tpandas.core.frame.DataFrame\n\t\t\"\"\"\n\n\t\tdf_cols = pd.DataFrame(self._obj.columns.tolist())\n\t\tdf_cols = df_cols.reset_index()\n\t\tdf_cols.columns = ['ColIndex', 'Col_Name']\n\t\treport_missing = self.isnull_list()\n\t\tdf_cols = df_cols.merge(report_missing, 'left', 'Col_Name')\n\n\t\treport_nunique = self.nunique()\n\t\tdf_cols = df_cols.merge(report_nunique, 'left', 'Col_Name')\n\n\t\treport_type = pd.DataFrame(self._obj.dtypes).reset_index()\n\t\treport_type.columns = ['Col_Name', 'Data_Type']\n\t\treport_type.Data_Type = report_type.Data_Type.map(lambda x: str(x))\n\t\tdf_cols = df_cols.merge(report_type, 'left', 'Col_Name')\n\t\treturn df_cols\n\n\n\tdef duplicated(self, colname_list: Union[str, list], return_dups=False, keep:bool=False) -&gt; int:\n\"\"\"\n\t\tTo count the duplicated rows, given a list of columns that contain the unique key.\n\n\t\tParameters\n\t\t----------\n\t\tcolname_list: Union[str, list]\n\n\t\treturn_dups: bool, optional\n\t\t\tDefault = False\n\t\t\tSet to True to return a tuple containing (count, df_duplicates).\n\n\t\tkeep: bool, optional\n\n\t\tReturns\n\t\t-------\n\t\tNumber of Duplicated Rows: int\n\t\t\"\"\"\n\t\tif isinstance(colname_list, list) == False:\n\t\t\tcolname_list = [colname_list]\n\n\t\tdf = self._obj\n\t\tif return_dups:\n\t\t\tdff = df[df.duplicated(subset=colname_list, keep=keep)]\n\t\t\tprint(len(dff))\n\t\t\treturn (dff)\n\t\telse:\n\t\t\treturn len(df[df.duplicated(subset=colname_list, keep=keep)])\n\n\n\tdef isnull(self, colname: str) -&gt; tuple:\n\"\"\"\n\t\tCount the rows (and the %) of missing values in the specified column\n\n\t\tParameters\n\t\t----------\n\t\tcolname: str\n\t\t\tSingle column name\n\n\t\tReturns\n\t\t-------\n\t\t(Count of Missing Rows, Percentage of Missing Rows): tuple\n\t\t\"\"\"\n\n\t\tdf = self._obj\n\t\ttemp = df[df[colname].isnull()]\n\t\treturn (len(temp), len(temp) / len(df))\n\n\n\tdef isnull_list(self, col_names_list=None) -&gt; pd.core.frame.DataFrame:\n\"\"\"\n\t\tGenerate a report of cases with missing values\n\n\t\tParameters\n\t\t----------\n\t\tcol_names_list: list, optional\n\t\t\tList of columns to be included in the report.\n\t\t\tIf not specified, all columns will be used.\n\n\n\t\tReturns\n\t\t-------\n\t\tpandas.core.frame.DataFrame\n\t\t\"\"\"\n\t\tdataframe_df = self._obj\n\t\tif type(dataframe_df) != pd.core.frame.DataFrame:\n\t\t\tprint('The method requires Pandas DataFrame as the input')\n\t\t\treturn\n\t\telse:\n\t\t\tif col_names_list == None:\n\t\t\t\tcol_names_list = dataframe_df.columns.tolist()\n\t\t\tif not isinstance(col_names_list, list):\n\t\t\t\tcol_names_list = [col_names_list]\n\n\t\t\tif len(col_names_list) &gt; 0:\n\t\t\t\tfetcher = []\n\t\t\t\tfor col in col_names_list:\n\t\t\t\t\ttupx = self.isnull(col)\n\t\t\t\t\tfetcher.append({'Col_Name': col, 'Missing_Count': tupx[0], 'Missing_Percentage': tupx[1]})\n\t\t\t\tfetcher = pd.DataFrame(fetcher)\n\t\t\t\treturn fetcher\n\t\t\telse:\n\t\t\t\tprint('There is no item in the columns')\n\t\t\t\treturn None\n\n\n\tdef nunique(self, col_names_list=None) -&gt; pd.core.frame.DataFrame:\n\"\"\"\n\t\tTo generate:\n\t\t\t1) the number of unique values\n\t\t\t2) the percentage of the unique value over the total records (or rows)\n\n\t\tParameters\n\t\t----------\n\t\tcol_names_list: list\n\t\t\tIf not specified, all column names will be used\n\n\t\tReturns\n\t\t-------\n\t\tpd.core.frame.DataFrame\n\t\t\"\"\"\n\t\tdf_input = self._obj\n\t\tif col_names_list is None:\n\t\t\tcol_names_list = df_input.columns.tolist()\n\t\tif len(col_names_list) &gt; 0:\n\t\t\tfetcher = []\n\t\t\tfor col in col_names_list:\n\t\t\t\tn = df_input[col].nunique()\n\t\t\t\tfetcher.append({'Col_Name': col, 'Unique_Values': n})\n\t\t\tfetcher = pd.DataFrame(fetcher)\n\t\t\tfetcher['Prcent_Unique_Values'] = fetcher.Unique_Values.map(lambda x: x / len(df_input))\n\t\t\treturn fetcher\n\n\n\tdef ci(self, col, n=1000, func=np.mean, p=0.05):\n\"\"\"\n\t\tGenerate 'n' bootstrap samples, evaluating `func` at each resampling.\n\t\tThis method returns a function, which can be called to obtain confidence intervals of interest.\n\t\tParameters\n\t\t----------\n\t\tn: int, optional\n\t\t\tsample size for the sampling distribution\n\t\t\t(defalt = 1,000)\n\n\t\tfunc: function, optional\n\t\t\tThe statistic functions to be bootstrapped its sampling distribution\n\t\t\t(default = np.mean())\n\n\t\tp: float, optional\n\t\t\tp-value for specifyin 2-sided symmetric confidence interval\n\n\t\tReturns\n\t\t-------\n\t\tfunction\n\t\t\tFunction to be called to obtain confidence intervals of interest.\n\t\t\tReturn 2-sided symmetric confidence interval specified\n\t\t\"\"\"\n\t\tdf = self._obj.copy()\n\t\tdata = df[col].copy()\n\t\tsimulations = list()\n\t\tsample_size = len(data)\n\t\txbar_init = np.mean(data)\n\t\tfor c in range(n):\n\t\t\titersample = np.random.choice(data, size=sample_size, replace=True)\n\t\t\tsimulations.append(func(itersample))\n\t\tsimulations.sort()\n\n\t\tdef ci(p):\n\t\t\tu_pval = (1 + p) / 2.\n\t\t\tl_pval = (1 - u_pval)\n\t\t\tl_indx = int(np.floor(n * l_pval))\n\t\t\tu_indx = int(np.floor(n * u_pval))\n\t\t\treturn (simulations[l_indx], simulations[u_indx])\n\t\treturn (ci)\n\n\n\tdef reset_index(self, index_label:str=\"RID\", inplace:bool=True):\n\"\"\"\n\t\tTo reset index and immediately rename the old 'index' to new index_label defined.\n\n\t\tParameters\n\t\t----------\n\t\tindex_label: str, optional\n\n\t\tinplace: bool, optional\n\n\t\tReturns\n\t\t-------\n\t\tpd.core.frame.DataFrame\n\t\t\tONLY when inplace == False\n\t\t\"\"\"\n\n\t\tdf_input = self._obj\n\t\tif inplace:\n\t\t\tdf = df_input\n\t\telse:\n\t\t\tdf = df_input.copy()\n\n\t\tdf.reset_index(inplace=True)\n\t\tdf.ds.rename('index', index_label)\n\n\t\tif inplace:\n\t\t\tdf_input = df.copy()\n\t\telse:\n\t\t\treturn df\n\n\n\tdef cols_shift(self, col_names:Union[str, list], direction:Union[str, int]= 'right'):\n\"\"\"\n\t\tTo shift a list of columns to the left-most or the right-most of the dataframe.\n\t\tNote: there is no \"inplace\" for this method.\n\n\t\tParameters\n\t\t----------\n\t\tcol_names: str or list\n\n\t\tdirection: str or int\n\t\t\tstr = 'left' or right\n\t\t\tint = 0 or 1\n\n\t\tinplace\n\n\t\tReturns\n\t\t-------\n\t\tdf with reordered columns: pd.core.frame.DataFrame\n\n\t\t\"\"\"\n\t\tdf_input = self._obj.copy()\n\n\t\tif not isinstance(col_names, list):\n\t\t\tcol_names = [col_names]\n\n\t\tdf_cols_list = df_input.columns.tolist().copy()\n\n\t\tfor col in col_names:\n\t\t\tdf_cols_list.remove(col)\n\n\t\tif (direction == 'right') | (direction == 1):\n\t\t\tdf_cols_list.extend(col_names)\n\t\t\tdf_input = df_input[df_cols_list].copy()\n\t\telif (direction == 'left') | (direction == 0):\n\t\t\tcol_names.extend(df_cols_list)\n\t\t\tdf_input = df_input[col_names].copy()\n\n\t\treturn df_input\n\n\n\n\tdef split(self, col:str, sep:str, index_label:str='RID',\n\t                                             drop_innerindex:bool=True, reset_index_inplace:bool=True):\n\"\"\"\n\t\tTo generate a DataFrame by splitting the values in a string, where the values are separated by a separator\n\t\tcharacter.\n\n\t\tThis method is improved upon the original split method in pandas. Where there is no separator in a row,\n\t\tthe value will still be posted to the newly generated DataFrame as the outputs.\n\n\t\tParameters\n\t\t----------\n\t\tcol: str\n\t\tsep: str\n\t\tindex_label: str\n\t\tdrop_innerindex: bool\n\t\treset_index_inplace\n\n\t\tReturns\n\t\t-------\n\t\tpd.core.frame.DataFrame\n\t\t\"\"\"\n\t\tif reset_index_inplace:\n\t\t\tdfo = self._obj\n\t\telse:\n\t\t\tdfo = self._obj.copy()\n\t\tdfo.reset_index(drop=True, inplace=True)\n\t\tdfo.ds.reset_index(index_label=index_label)\n\n\t\tdf = dfo.copy()\n\t\tdf[col + \"_splitready\"] = df[col].map(lambda x: str(x) + sep if sep not in str(x) else str(x))\n\t\tdf = df[[index_label, col + \"_splitready\"]].copy()\n\t\tdf.set_index(index_label, inplace=True)\n\t\tdf = df[col + \"_splitready\"].str.split(sep, expand=True).stack().reset_index()\n\t\tdf.columns = [index_label, 'InnerIndex', col]\n\n\t\tdf[col] = df[col].str.replace(sep, '')\n\t\tdf[col] = df[col].replace('', np.nan)\n\t\tdf.dropna(subset=[col], inplace=True)\n\n\t\tdf[col] = df[col].str.strip()\n\n\t\tif drop_innerindex:\n\t\t\tdf.drop('InnerIndex', 'columns', inplace=True)\n\n\t\treturn df\n\n\n\tdef rename(self, col_index_or_name:Union[str, int], col_name_new, inplace:bool=True):\n\"\"\"\n\t\tTo rename single column\n\t\tParameters\n\t\t----------\n\t\tcol_index_or_name\n\t\tcol_name_new\n\t\tinplace\n\n\t\tReturns\n\t\t-------\n\t\trenamed_DataFrame: pd.core.frame.DataFrame\n\t\t\tOnly if inplace is set to False.\n\t\t\"\"\"\n\t\tdf_input = self._obj\n\t\tif inplace:\n\t\t\tdf = df_input\n\t\telse:\n\t\t\tdf = df_input.copy()\n\n\t\tif str(col_index_or_name).isnumeric() == True:\n\t\t\tcolName_Old = df.columns.tolist()[col_index_or_name]\n\t\telse:\n\t\t\tcolName_Old = col_index_or_name\n\n\t\tif colName_Old in [col for col in df.columns.tolist()]:\n\t\t\tdf.rename(columns={colName_Old: col_name_new}, inplace=True)\n\t\telse:\n\t\t\tprint(\"Error: The \" + colName_Old + \" is not an existing column name.\")\n\n\t\tif inplace:\n\t\t\tdf_input = df.copy()\n\t\telse:\n\t\t\treturn df\n\n\n\tdef to_dict(self, key_col:str, val_col:str) -&gt; pd.core.frame.DataFrame:\n\"\"\"\n\t\tTo generate dictionary from two columns\n\t\tParameters\n\t\t----------\n\t\tkey_col: str\n\t\tval_col: str\n\n\t\tReturns\n\t\t-------\n\t\tpd.core.frame.DataFrame\n\t\t\"\"\"\n\t\tdf = self._obj\n\t\tdict = {}\n\t\tfor index, row in df.iterrows():\n\t\t\tdict[row[key_col]] = row[val_col]\n\t\treturn dict\n\n\n\tdef _df_convert_date_columns_to_pandas_date(self, keyword='date', cols_list=None, inplace=False):\n\"\"\"\n\t\tTo conver columns with \"date\" (non-case sensitive) in DataFrame into Pandas DateTimes type.\n\t\tIf the &lt;&lt;cols_list&gt;&gt; paramater is provided, the &lt;&lt;keyword&gt;&gt; parameter will be ignored\n\n\t\tParameters\n\t\t----------\n\t\tkeyword\n\t\tcols_list\n\t\tinplace\n\n\t\tReturns\n\t\t-------\n\n\t\t\"\"\"\n\t\tdf_input = self._obj\n\t\tif inplace:\n\t\t\tdf = df_input\n\t\telse:\n\t\t\tdf = df_input.copy()\n\n\t\tif cols_list != None:\n\t\t\tif isinstance(cols_list, Iterable):\n\t\t\t\tdate_Cols = cols_list\n\t\telse:\n\t\t\tdate_Cols = [col for col in df.columns.tolist() if keyword in col.lower()]\n\t\tfor col in date_Cols:\n\t\t\ttry:\n\t\t\t\tdf[col] = pd.to_datetime(df[col])\n\t\t\t\tprint(\"Converted Column - \" + str(col))\n\t\t\texcept:\n\t\t\t\tprint(\"Conversation Failed for Column - \" + str(col))\n\n\t\tif not inplace:\n\t\t\treturn df\n\n\n\n\tdef cumsum(self, col_name: str) -&gt; pd.core.frame.DataFrame:\n\"\"\"\n\t\t To generates the following using the unique values of a variable:\n\t\t - Count (Raw Count of Records)\n\t\t - Percentage of the values over the total data\n\t\t - Accumulated percentage of the values\n\t\tParameters\n\t\t----------\n\t\tcol_name: str\n\n\t\tReturns\n\t\t-------\n\t\tpd.core.frame.DataFrame\n\t\t\"\"\"\n\t\tdf = self._obj.copy()\n\t\t#df = df.fillna('Missing_Value')\n\t\tinnerTemp = pd.DataFrame(df[col_name].value_counts()).reset_index()\n\t\tinnerTemp.sort_values(['index'], 'index', inplace=True)\n\t\tinnerTemp['Records_Percent'] = innerTemp[col_name] / len(df)\n\t\tinnerTemp.sort_values('Records_Percent', 0, False, inplace=True)\n\t\tinnerTemp['Accum_Percent'] = innerTemp['Records_Percent'].cumsum()\n\t\tinnerTemp.columns = [col_name, 'Records_Count', 'Records_Percent', 'Accum_Percent']\n\t\treturn innerTemp\n\n\n\n\tdef _to_excel_exists(self, filepath_incl_extension, tab_name, index=False):\n\"\"\"\n\t\tTo insert a DataFrame into a new worksheet in an existing excel file.\n\t\tThe method use 'openpyxl' as the writer engine.\n\n\t\tParameters\n\t\t----------\n\t\tfilepath_incl_extension: str\n\t\ttab_name: str\n\t\tindex: bool\n\n\t\tReturns\n\t\t-------\n\n\t\t\"\"\"\n\t\twriter = pd.ExcelWriter(filepath_incl_extension, engine='xlsxwriter')\n\t\tdf = self._obj.copy()\n\t\tdf.to_excel(writer, sheet_name=tab_name)\n\t\twriter.save()\n\n\n\tdef to_excel_stringify(self, dir=None, strings_to_urls_bool=False):\n\"\"\"\n\t\tFaster option to export Excel File, with the option to stringify all hyperlinks in the table.\n\t\tParameters\n\t\t----------\n\t\tdir\n\t\tstrings_to_urls_bool\n\n\t\tReturns\n\t\t-------\n\n\t\t\"\"\"\n\t\tif dir is None:\n\t\t\tdir = self.dir_data\n\n\t\twriter = pd.ExcelWriter(dir, engine='xlsxwriter', options={'strings_to_urls': strings_to_urls_bool})\n\t\tself._obj.to_excel(writer)\n\t\twriter.close()\n\t\tprint(\"Exported Excel File to \" + dir)\n\n\n\tdef dump(self, path:str, compression_level:int=7):\n\"\"\"\n\t\tTo dump DataFrame to the project's data/temp directory\n\n\t\tParameters\n\t\t----------\n\t\tpath: str\n\t\tdir: str, optional\n\t\t\tDefault = data/temp\n\n\t\tcompression_level: int, optional\n\n\t\tReturns\n\t\t-------\n\t\tNone\n\t\t\"\"\"\n\t\tdf = self._obj\n\n\t\tif '/' not in path:\n\t\t\tdir = os.path.join(self.dir_data, 'temp', path)\n\t\telse:\n\t\t\tdir = path\n\n\t\tdump(df, dir + \".df\", compress=('gzip', compression_level))\n\t\tprint(\"Compressed dump created at \" + os.path.dirname(dir) + \" | filename = \" + os.path.basename(dir + \".df\"))\n\n\n\tdef cols_datetime_to_string(self, inplace=False):\n\t\tdf_input = self._obj.copy()\n\t\tif inplace:\n\t\t\tdf = df_input\n\t\telse:\n\t\t\tdf = df_input.copy()\n\t\tdtypex = pd.DataFrame(df.dtypes).reset_index()\n\t\tdtypex.columns = ['Colname', 'Type']\n\t\tdtypex.Type = dtypex.Type.astype(str)\n\t\tdtypex = dtypex[dtypex.Type.str.contains('date')]\n\t\tfor col in dtypex.Colname.tolist():\n\t\t\tdf[col] = df[col].astype(str)\n\t\t\tprint(\"Converted {}\".format(col))\n\n\t\tif inplace:\n\t\t\tdf_input = df.copy()\n\t\telse:\n\t\t\treturn df\n\n\n\tdef convert_dtypes(self):\n\"\"\"\n\t\tTo convert dtypes to Pandas 1.0 dtypes and stringify object columns\n\n\t\tReturns\n\t\t-------\n\t\tpd.core.frame.DataFrame\n\t\t\"\"\"\n\t\tdf = self._obj.copy()\n\t\tdf = df.convert_dtypes()\n\t\tdf_types = pd.DataFrame(df.dtypes).reset_index()\n\t\tdf_types.columns = ['colname', 'datatype']\n\t\tdf_types.datatype = df_types.datatype.astype(str)\n\t\tdf_types = df_types[df_types.datatype.str.contains('datetime')]\n\t\tif len(df_types):\n\t\t\tfor col in df_types.colname:\n\t\t\t\tdf[col] = df[col].astype(str)\n\t\treturn df.copy()\n\n\n\tdef to_xv(self, title=None, convert_time:bool=True, dirbase=\"_temp\"):\n\t\t#import webbrowser\n\t\tdf = self._obj\n\t\tif convert_time:\n\t\t\tdf = df.ds.cols_datetime_to_string(inplace=False)\n\n\t\tif title is None:\n\t\t\ttitle = 'LabView'\n\t\t\thtml_filename = 'LabView'\n\t\telse:\n\t\t\thtml_filename = 'LabView_' + str(title)\n\n\n\t\t# Writing data to disk\n\t\tjsonstr = df.to_json(orient='records')\n\t\tdata_var = \"var data = {};\".format(jsonstr)\n\n\n\t\tbase_file = os.path.join(dirbase, 'xbase.html')\n\t\thtmlfile = open(base_file, 'r')\n\t\thtmlstring = htmlfile.read()\n\t\thtmlfile.close()\n\n\t\t# In the &lt;script&gt; tag which points to the external data.js\n\t\t#htmlstring = htmlstring.replace('data.js', str(data_filename) + '.js', 1)\n\t\thtmlstring = htmlstring.replace('LabView', str(title), 1)\n\t\thtmlstring = htmlstring.replace('e=\"insert_data_here\";', data_var, 1)\n\n\n\t\tnewfile = open(os.path.join(dirbase, html_filename + '.html'), 'w')\n\t\tnewfile.write(htmlstring)\n\t\tnewfile.close()\n\t\treturn html_filename\n\t\t#webbrowser.get(dsx.path_chrome).open(path_string)\n\n\n\tdef xv(self, title=None, convert_time=True, width=\"100%\", height=\"1200\", dirhtml=\"../_temp\", dirbase=\"_temp\", **kwargs):\n\"\"\"\n\n\t\tParameters\n\t\t----------\n\t\ttitle: str, Title for the new viewer file.\n\n\t\tconvert: bool, Convert datetime dtype to str for display.\n\n\n\t\tReturns\n\t\t-------\n\n\t\t\"\"\"\n\t\tfrom IPython.display import IFrame\n\t\tviewer_filename = self._obj.ds.to_xv(title, convert_time=convert_time, dirbase=dirbase)\n\t\treturn IFrame(os.path.join(dirbase, (viewer_filename+'.html')), width=width, height=height)\n\n\n\n\t@classmethod\n\tdef _modify_vizdatafile(cls, data_filename='data', viewer_filename=None, dir_file=None):\n\"\"\"\n\t\tDepecirated Method\n\t\tA private classmethod for changing the data.js configuration in the js and the html files.\n\n\t\tParameters\n\t\t----------\n\t\tfilename\n\t\tdir_file\n\n\t\tReturns\n\t\t-------\n\n\t\t\"\"\"\n\t\tif dir_file is None:\n\t\t\tdir_file = '_temp/xbox.html'\n\t\thtmlfile = open(dir_file, 'r')\n\t\thtmlstring = htmlfile.read()\n\t\thtmlfile.close()\n\n\t\t# In the &lt;script&gt; tag which points to the external data.js\n\t\thtmlstring = htmlstring.replace('data.js', str(data_filename) + '.js', 1)\n\t\thtmlstring = htmlstring.replace('title_to_replace', str(data_filename), 1)\n\n\t\tdir_name = os.path.dirname(dir_file)\n\t\tnewfile = open(os.path.join(dir_name, data_filename + '.html'), 'w')\n\t\tnewfile.write(htmlstring)\n\t\tnewfile.close()\n\n\n\tdef get_dfname(self, set=True):\n\"\"\"\n\t\tTo get name of the variable.\n\n\n\t\tOnly work in iPython.\n\n\t\tParameters\n\t\t----------\n\t\tvar\n\n\t\tReturns\n\t\t-------\n\t\tvariable_name: str\n\t\t\"\"\"\n\t\tcallers_local_vars = inspect.currentframe().f_back.f_locals.items()\n\t\tname = [var_name for var_name, var_val in callers_local_vars if var_val is self._obj][0]\n\t\tif set:\n\t\t\tself._obj.name = name\n\t\treturn name\n\n\n\t@staticmethod\n\tdef get_varname(var:object):\n\"\"\"\n\t\tTo get name of the variable.\n\n\t\tOnly work in iPython.\n\n\t\tParameters\n\t\t----------\n\t\tvar\n\n\t\tReturns\n\t\t-------\n\t\tvariable_name: str\n\t\t\"\"\"\n\t\tcallers_local_vars = inspect.currentframe().f_back.f_locals.items()\n\t\treturn [var_name for var_name, var_val in callers_local_vars if var_val is var][0]\n\n\n\t@staticmethod\n\tdef interactive():\n\"\"\"\n\t\tSet InteractiveShell.ast_node_interactivity = \"all\"\n\t\tSet mpl.use(\"module://backend_interagg\")\n\t\tSet plt.ion()\n\n\t\t\"\"\"\n\t\tfrom IPython.core.interactiveshell import InteractiveShell\n\t\tInteractiveShell.ast_node_interactivity = \"all\"\n\t\tmpl.use(\"module://backend_interagg\")\n\t\tplt.ion()\n\t\tprint(\"Package loaded in Non-Notebook Mode | mpl.use('module://backend_interagg') | plt.ion()\" )\n\n\n\t@staticmethod\n\tdef plt_labels(percent=False, fontsize=None, color=None, denominator=None):\n\"\"\"\n\t\tTo insert label for each element in the current axes (last chart created).\n\t\tParameters\n\t\t----------\n\t\tpercent: bool\n\t\tfontsize: float\n\t\tcolor: str\n\t\tdenominator: float\n\n\t\tReturns\n\t\t-------\n\t\tNone\n\t\t\"\"\"\n\t\tax = plt.gca()\n\t\tfor p in ax.patches:\n\t\t\tif percent:\n\t\t\t\tax.text(p.get_x() + (p.get_width() / 2), p.get_height(), round(p.get_height() / denominator * 100, 1),\n\t\t\t\t        ha='center', va='bottom')\n\t\t\telse:\n\t\t\t\tax.text(p.get_x() + (p.get_width() / 2), p.get_height(), p.get_height(), ha='center', va='bottom')\n\n\n\n\t@classmethod\n\tdef activate_lolviz(cls):\n\"\"\"\n\t\tImport lolviz package as lz.\n\t\tAdd graphviz directory to the os.environ[\"path\"].\n\n\t\tParameters\n\t\t----------\n\t\tlolviz_dir: str, optional\n\n\t\tReturns\n\t\t-------\n\t\tlolviz instance\n\t\t\"\"\"\n\t\twarnings.warn('This will be deprecated', PendingDeprecationWarning)\n\t\t# lolviz_dir='C:/Program Files (x86)/Graphviz2.38/bin/'\n\t\timport lolviz as lz\n\t\tos.environ[\"PATH\"] += os.pathsep + dsx.path_graphviz\n\t\tprint('Activate lolviz with path {}'.format(dsx.path_graphviz))\n\t\treturn lz\n\n\n\t@classmethod\n\tdef set_dirs(cls, root=False):\n\"\"\"\n\t\tSet the project root folder.\n\n\t\tParameters\n\t\t----------\n\t\troot: bool, optional\n\t\t\tTo indicate whether the current active directory is the root or sub-directory of the project\n\n\t\tReturns\n\t\t-------\n\t\tNone\n\t\t\"\"\"\n\n\t\tdir = None\n\t\tif root:\n\t\t\tdir = os.getcwd()\n\t\telse:\n\t\t\tdir = os.path.join(os.getcwd(), \"..\")\n\t\tos.chdir(dir)\n\n\t\tcls.dir_project = os.getcwd()\n\t\tcls.dir_data = os.path.join(cls.dir_project, 'data')\n\t\tcls.dir_temp = os.path.join(cls.dir_project, '_temp')\n\n\t\tprint('Set project directory to {}.'.format(os.getcwd()))\n\t\tprint('Property \"dir_%\" enabled')\n\n\n\t@classmethod\n\tdef setup_project(cls, root=True, get_xfiles=False, xfiles_url=None, git_files=False):\n\"\"\"\n\t\tSetup project directories for new projects.\n\t\tIf the directories exist, will not be overwritten.\n\n\t\tParameters\n\t\t----------\n\t\troot: bool, optional\n\t\tget_xfiles: bool, optional\n\t\tgit_files: bool, optional\n\n\t\tReturns\n\t\t-------\n\t\tNone\n\t\t\"\"\"\n\t\t#cls.set_dirs(root=root)\n\t\tcls.dir_project = os.getcwd()\n\t\tcls.dir_data = os.path.join(cls.dir_project, 'data')\n\t\tcls.dir_temp = os.path.join(cls.dir_project, '_temp')\n\n\t\tfolders = ['data', 'data/temp', 'data/inputs', 'data/outputs', 'notebooks', '_temp']\n\t\tfor folder in folders:\n\t\t\tif os.path.exists(os.path.join(cls.dir_project, folder)) == False:\n\t\t\t\tos.mkdir(os.path.join(cls.dir_project, folder))\n\t\tprint('Created project structure')\n\n\n\t\tif get_xfiles:\n\t\t\tos.mkdir(os.path.join(cls.dir_project, '_temp'))\n\n\t\t\tos.chdir(cls.dir_temp)\n\t\t\tif not os.path.exists('xbase.html'):\n\t\t\t\timport urllib\n\t\t\t\turllib.request.urlretrieve(xfiles_url, 'xbase.html')\n\n\n\t\t\tos.chdir(cls.dir_project)\n\t\t\tprint('Downloaded Extra Files.')\n\n\n\t@classmethod\n\tdef del_tempfiles(cls, tempdata=False):\n\"\"\"\n\t\tStatic method: To delete temporary files of the projects.\n\n\t\tParameters\n\t\t----------\n\t\ttempdata: bool, optional\n\t\t\tDefault is 'False'. Set to 'True' to delete temporary data in 'data/temp' directory\n\n\t\tReturns\n\t\t-------\n\t\tNone\n\t\t\"\"\"\n\t\timport shutil\n\t\ttry:\n\t\t\tpath = os.path.join(cls.dir_data, 'temp')\n\t\t\tif os.path.exists(path):\n\t\t\t\tshutil.rmtree(path)\n\t\t\t\tprint('Deleted data/temp')\n\n\t\t\tif os.path.exists(cls.dir_temp):\n\t\t\t\tshutil.rmtree(cls.dir_temp)\n\t\t\t\tprint('Deleted _temp')\n\t\texcept:\n\t\t\tprint(\"Removed files. Directories may remain\")\n\n\n\t@staticmethod\n\tdef matplotlib_config():\n\"\"\"\n\t\tPrint matplotlib configurations\n\n\t\tReturns\n\t\t-------\n\t\tlines of texts: str\n\n\t\t\"\"\"\n\t\tprint('%matplotlib inline')\n\t\tprint(\"%config InlineBackend.figure_format = 'retina'\")\n\t\tprint(\"sns.set_style('fivethirtyeight')\")\n\t\tprint(\"plt.rc('figure', figsize=(16,9))\")\n\t\tprint(\"sns.set_context(context={'figure.figsize': (16,9)})\")\n\t\tprint(\"plt.style.use('fivethirtyeight')\")\n\n\t@staticmethod\n\tdef qgrid_config():\n\t\tprint(\"qgrid.set_grid_option('forceFitColumns', False)\")\n\n\n\t@staticmethod\n\tdef set_ipython(node_interactivity:str='last'):\n\"\"\"\n\t\tSet ast_node_interactivity in Ipython.core.InteractiveShell\n\n\t\tParameters\n\t\t----------\n\t\tnode_interactivity: str, optional\n\t\t\tDefault is 'last'. DSX uses 'all' if kernel is detected.\n\n\t\tReturns\n\t\t---\n\t\tNone\n\n\t\t\"\"\"\n\t\tfrom IPython.core.interactiveshell import InteractiveShell\n\t\tInteractiveShell.ast_node_interactivity = node_interactivity\n\n\t@staticmethod\n\tdef set_pandas_display(max_rows: int = 25):\n\t\tpd.set_option('display.max_rows', max_rows)\n\t\tprint(f'Set \"display.max_rows\" as {max_rows}')\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.activate_lolviz","title":"<code>activate_lolviz()</code>  <code>classmethod</code>","text":"<p>Import lolviz package as lz. Add graphviz directory to the os.environ[\"path\"].</p>"},{"location":"reference/#dsx.ds_utils.dsx.activate_lolviz--parameters","title":"Parameters","text":"<p>lolviz_dir: str, optional</p>"},{"location":"reference/#dsx.ds_utils.dsx.activate_lolviz--returns","title":"Returns","text":"<p>lolviz instance</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>@classmethod\ndef activate_lolviz(cls):\n\"\"\"\n\tImport lolviz package as lz.\n\tAdd graphviz directory to the os.environ[\"path\"].\n\n\tParameters\n\t----------\n\tlolviz_dir: str, optional\n\n\tReturns\n\t-------\n\tlolviz instance\n\t\"\"\"\n\twarnings.warn('This will be deprecated', PendingDeprecationWarning)\n\t# lolviz_dir='C:/Program Files (x86)/Graphviz2.38/bin/'\n\timport lolviz as lz\n\tos.environ[\"PATH\"] += os.pathsep + dsx.path_graphviz\n\tprint('Activate lolviz with path {}'.format(dsx.path_graphviz))\n\treturn lz\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.ci","title":"<code>ci(col, n=1000, func=np.mean, p=0.05)</code>","text":"<p>Generate 'n' bootstrap samples, evaluating <code>func</code> at each resampling. This method returns a function, which can be called to obtain confidence intervals of interest. Parameters</p> int, optional <p>sample size for the sampling distribution (defalt = 1,000)</p> function, optional <p>The statistic functions to be bootstrapped its sampling distribution (default = np.mean())</p> float, optional <p>p-value for specifyin 2-sided symmetric confidence interval</p>"},{"location":"reference/#dsx.ds_utils.dsx.ci--returns","title":"Returns","text":"<p>function         Function to be called to obtain confidence intervals of interest.         Return 2-sided symmetric confidence interval specified</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def ci(self, col, n=1000, func=np.mean, p=0.05):\n\"\"\"\n\tGenerate 'n' bootstrap samples, evaluating `func` at each resampling.\n\tThis method returns a function, which can be called to obtain confidence intervals of interest.\n\tParameters\n\t----------\n\tn: int, optional\n\t\tsample size for the sampling distribution\n\t\t(defalt = 1,000)\n\n\tfunc: function, optional\n\t\tThe statistic functions to be bootstrapped its sampling distribution\n\t\t(default = np.mean())\n\n\tp: float, optional\n\t\tp-value for specifyin 2-sided symmetric confidence interval\n\n\tReturns\n\t-------\n\tfunction\n\t\tFunction to be called to obtain confidence intervals of interest.\n\t\tReturn 2-sided symmetric confidence interval specified\n\t\"\"\"\n\tdf = self._obj.copy()\n\tdata = df[col].copy()\n\tsimulations = list()\n\tsample_size = len(data)\n\txbar_init = np.mean(data)\n\tfor c in range(n):\n\t\titersample = np.random.choice(data, size=sample_size, replace=True)\n\t\tsimulations.append(func(itersample))\n\tsimulations.sort()\n\n\tdef ci(p):\n\t\tu_pval = (1 + p) / 2.\n\t\tl_pval = (1 - u_pval)\n\t\tl_indx = int(np.floor(n * l_pval))\n\t\tu_indx = int(np.floor(n * u_pval))\n\t\treturn (simulations[l_indx], simulations[u_indx])\n\treturn (ci)\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.cols_shift","title":"<code>cols_shift(col_names, direction='right')</code>","text":"<p>To shift a list of columns to the left-most or the right-most of the dataframe. Note: there is no \"inplace\" for this method.</p>"},{"location":"reference/#dsx.ds_utils.dsx.cols_shift--parameters","title":"Parameters","text":"<p>col_names: str or list</p> str or int <p>str = 'left' or right int = 0 or 1</p> <p>inplace</p>"},{"location":"reference/#dsx.ds_utils.dsx.cols_shift--returns","title":"Returns","text":"<p>df with reordered columns: pd.core.frame.DataFrame</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def cols_shift(self, col_names:Union[str, list], direction:Union[str, int]= 'right'):\n\"\"\"\n\tTo shift a list of columns to the left-most or the right-most of the dataframe.\n\tNote: there is no \"inplace\" for this method.\n\n\tParameters\n\t----------\n\tcol_names: str or list\n\n\tdirection: str or int\n\t\tstr = 'left' or right\n\t\tint = 0 or 1\n\n\tinplace\n\n\tReturns\n\t-------\n\tdf with reordered columns: pd.core.frame.DataFrame\n\n\t\"\"\"\n\tdf_input = self._obj.copy()\n\n\tif not isinstance(col_names, list):\n\t\tcol_names = [col_names]\n\n\tdf_cols_list = df_input.columns.tolist().copy()\n\n\tfor col in col_names:\n\t\tdf_cols_list.remove(col)\n\n\tif (direction == 'right') | (direction == 1):\n\t\tdf_cols_list.extend(col_names)\n\t\tdf_input = df_input[df_cols_list].copy()\n\telif (direction == 'left') | (direction == 0):\n\t\tcol_names.extend(df_cols_list)\n\t\tdf_input = df_input[col_names].copy()\n\n\treturn df_input\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.cols_std","title":"<code>cols_std(inplace=True, lower=False)</code>","text":"<pre><code>    To standardize the names of all columns, to be compatible with iPython.\n    This method removes space and special characterss in the column names.\n    After standardized, the column names can be used as attribute of the DataFrame (with autocomplete) in iPython\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.cols_std--parameters","title":"Parameters","text":"<p>inplace: bool</p> <p>camel: bool</p>"},{"location":"reference/#dsx.ds_utils.dsx.cols_std--returns","title":"Returns","text":"<p>pandas.core.frame.DataFrame         Only when inplace parameter is set to False</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def cols_std(self, inplace=True, lower=False):\n\"\"\"\n\t\tTo standardize the names of all columns, to be compatible with iPython.\n\t\tThis method removes space and special characterss in the column names.\n\t\tAfter standardized, the column names can be used as attribute of the DataFrame (with autocomplete) in iPython\n\n\tParameters\n\t----------\n\tinplace: bool\n\n\tcamel: bool\n\n\n\tReturns\n\t-------\n\tpandas.core.frame.DataFrame\n\t\tOnly when inplace parameter is set to False\n\t\"\"\"\n\tdf_input = self._obj\n\tif inplace:\n\t\tdf = df_input\n\telse:\n\t\tdf = df_input.copy()\n\timport re\n\tpat = re.compile(r'[\\W]+')\n\tdf.columns = df.columns.str.replace(pat, '_')\n\tdf.columns = df.columns.str.strip('_')\n\tpat_Multi_Underscore = re.compile(r'[_]{2,}')\n\tdf.columns = df.columns.str.replace(pat_Multi_Underscore, '_')\n\tif lower == True:\n\t\tdf.columns = df.columns.str.lower()\n\n\tif inplace:\n\t\tdf_input = df.copy()\n\telse:\n\t\treturn df\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.convert_dtypes","title":"<code>convert_dtypes()</code>","text":"<p>To convert dtypes to Pandas 1.0 dtypes and stringify object columns</p>"},{"location":"reference/#dsx.ds_utils.dsx.convert_dtypes--returns","title":"Returns","text":"<p>pd.core.frame.DataFrame</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def convert_dtypes(self):\n\"\"\"\n\tTo convert dtypes to Pandas 1.0 dtypes and stringify object columns\n\n\tReturns\n\t-------\n\tpd.core.frame.DataFrame\n\t\"\"\"\n\tdf = self._obj.copy()\n\tdf = df.convert_dtypes()\n\tdf_types = pd.DataFrame(df.dtypes).reset_index()\n\tdf_types.columns = ['colname', 'datatype']\n\tdf_types.datatype = df_types.datatype.astype(str)\n\tdf_types = df_types[df_types.datatype.str.contains('datetime')]\n\tif len(df_types):\n\t\tfor col in df_types.colname:\n\t\t\tdf[col] = df[col].astype(str)\n\treturn df.copy()\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.cumsum","title":"<code>cumsum(col_name)</code>","text":"<p>To generates the following using the unique values of a variable:  - Count (Raw Count of Records)  - Percentage of the values over the total data  - Accumulated percentage of the values Parameters</p> <p>col_name: str</p>"},{"location":"reference/#dsx.ds_utils.dsx.cumsum--returns","title":"Returns","text":"<p>pd.core.frame.DataFrame</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def cumsum(self, col_name: str) -&gt; pd.core.frame.DataFrame:\n\"\"\"\n\t To generates the following using the unique values of a variable:\n\t - Count (Raw Count of Records)\n\t - Percentage of the values over the total data\n\t - Accumulated percentage of the values\n\tParameters\n\t----------\n\tcol_name: str\n\n\tReturns\n\t-------\n\tpd.core.frame.DataFrame\n\t\"\"\"\n\tdf = self._obj.copy()\n\t#df = df.fillna('Missing_Value')\n\tinnerTemp = pd.DataFrame(df[col_name].value_counts()).reset_index()\n\tinnerTemp.sort_values(['index'], 'index', inplace=True)\n\tinnerTemp['Records_Percent'] = innerTemp[col_name] / len(df)\n\tinnerTemp.sort_values('Records_Percent', 0, False, inplace=True)\n\tinnerTemp['Accum_Percent'] = innerTemp['Records_Percent'].cumsum()\n\tinnerTemp.columns = [col_name, 'Records_Count', 'Records_Percent', 'Accum_Percent']\n\treturn innerTemp\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.del_tempfiles","title":"<code>del_tempfiles(tempdata=False)</code>  <code>classmethod</code>","text":"<p>Static method: To delete temporary files of the projects.</p>"},{"location":"reference/#dsx.ds_utils.dsx.del_tempfiles--parameters","title":"Parameters","text":"bool, optional <p>Default is 'False'. Set to 'True' to delete temporary data in 'data/temp' directory</p>"},{"location":"reference/#dsx.ds_utils.dsx.del_tempfiles--returns","title":"Returns","text":"<p>None</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>@classmethod\ndef del_tempfiles(cls, tempdata=False):\n\"\"\"\n\tStatic method: To delete temporary files of the projects.\n\n\tParameters\n\t----------\n\ttempdata: bool, optional\n\t\tDefault is 'False'. Set to 'True' to delete temporary data in 'data/temp' directory\n\n\tReturns\n\t-------\n\tNone\n\t\"\"\"\n\timport shutil\n\ttry:\n\t\tpath = os.path.join(cls.dir_data, 'temp')\n\t\tif os.path.exists(path):\n\t\t\tshutil.rmtree(path)\n\t\t\tprint('Deleted data/temp')\n\n\t\tif os.path.exists(cls.dir_temp):\n\t\t\tshutil.rmtree(cls.dir_temp)\n\t\t\tprint('Deleted _temp')\n\texcept:\n\t\tprint(\"Removed files. Directories may remain\")\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.dump","title":"<code>dump(path, compression_level=7)</code>","text":"<p>To dump DataFrame to the project's data/temp directory</p>"},{"location":"reference/#dsx.ds_utils.dsx.dump--parameters","title":"Parameters","text":"<p>path: str</p> str, optional <p>Default = data/temp</p> <p>compression_level: int, optional</p>"},{"location":"reference/#dsx.ds_utils.dsx.dump--returns","title":"Returns","text":"<p>None</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def dump(self, path:str, compression_level:int=7):\n\"\"\"\n\tTo dump DataFrame to the project's data/temp directory\n\n\tParameters\n\t----------\n\tpath: str\n\tdir: str, optional\n\t\tDefault = data/temp\n\n\tcompression_level: int, optional\n\n\tReturns\n\t-------\n\tNone\n\t\"\"\"\n\tdf = self._obj\n\n\tif '/' not in path:\n\t\tdir = os.path.join(self.dir_data, 'temp', path)\n\telse:\n\t\tdir = path\n\n\tdump(df, dir + \".df\", compress=('gzip', compression_level))\n\tprint(\"Compressed dump created at \" + os.path.dirname(dir) + \" | filename = \" + os.path.basename(dir + \".df\"))\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.duplicated","title":"<code>duplicated(colname_list, return_dups=False, keep=False)</code>","text":"<p>To count the duplicated rows, given a list of columns that contain the unique key.</p>"},{"location":"reference/#dsx.ds_utils.dsx.duplicated--parameters","title":"Parameters","text":"<p>colname_list: Union[str, list]</p> bool, optional <p>Default = False Set to True to return a tuple containing (count, df_duplicates).</p> <p>keep: bool, optional</p>"},{"location":"reference/#dsx.ds_utils.dsx.duplicated--returns","title":"Returns","text":"<p>Number of Duplicated Rows: int</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def duplicated(self, colname_list: Union[str, list], return_dups=False, keep:bool=False) -&gt; int:\n\"\"\"\n\tTo count the duplicated rows, given a list of columns that contain the unique key.\n\n\tParameters\n\t----------\n\tcolname_list: Union[str, list]\n\n\treturn_dups: bool, optional\n\t\tDefault = False\n\t\tSet to True to return a tuple containing (count, df_duplicates).\n\n\tkeep: bool, optional\n\n\tReturns\n\t-------\n\tNumber of Duplicated Rows: int\n\t\"\"\"\n\tif isinstance(colname_list, list) == False:\n\t\tcolname_list = [colname_list]\n\n\tdf = self._obj\n\tif return_dups:\n\t\tdff = df[df.duplicated(subset=colname_list, keep=keep)]\n\t\tprint(len(dff))\n\t\treturn (dff)\n\telse:\n\t\treturn len(df[df.duplicated(subset=colname_list, keep=keep)])\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.get_dfname","title":"<code>get_dfname(set=True)</code>","text":"<p>To get name of the variable.</p> <p>Only work in iPython.</p>"},{"location":"reference/#dsx.ds_utils.dsx.get_dfname--parameters","title":"Parameters","text":"<p>var</p>"},{"location":"reference/#dsx.ds_utils.dsx.get_dfname--returns","title":"Returns","text":"<p>variable_name: str</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def get_dfname(self, set=True):\n\"\"\"\n\tTo get name of the variable.\n\n\n\tOnly work in iPython.\n\n\tParameters\n\t----------\n\tvar\n\n\tReturns\n\t-------\n\tvariable_name: str\n\t\"\"\"\n\tcallers_local_vars = inspect.currentframe().f_back.f_locals.items()\n\tname = [var_name for var_name, var_val in callers_local_vars if var_val is self._obj][0]\n\tif set:\n\t\tself._obj.name = name\n\treturn name\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.get_varname","title":"<code>get_varname(var)</code>  <code>staticmethod</code>","text":"<p>To get name of the variable.</p> <p>Only work in iPython.</p>"},{"location":"reference/#dsx.ds_utils.dsx.get_varname--parameters","title":"Parameters","text":"<p>var</p>"},{"location":"reference/#dsx.ds_utils.dsx.get_varname--returns","title":"Returns","text":"<p>variable_name: str</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>@staticmethod\ndef get_varname(var:object):\n\"\"\"\n\tTo get name of the variable.\n\n\tOnly work in iPython.\n\n\tParameters\n\t----------\n\tvar\n\n\tReturns\n\t-------\n\tvariable_name: str\n\t\"\"\"\n\tcallers_local_vars = inspect.currentframe().f_back.f_locals.items()\n\treturn [var_name for var_name, var_val in callers_local_vars if var_val is var][0]\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.info","title":"<code>info()</code>","text":"<p>To generate the meta-data of the DataFrame. Meta-data includes the following: - Column Names - Missing Count - Missing Percentage - Unique Value Count (nunique) - Unique Value Percentage</p>"},{"location":"reference/#dsx.ds_utils.dsx.info--returns","title":"Returns","text":"<p>pandas.core.frame.DataFrame</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def info(self):\n\"\"\"\n\tTo generate the meta-data of the DataFrame.\n\tMeta-data includes the following:\n\t- Column Names\n\t- Missing Count\n\t- Missing Percentage\n\t- Unique Value Count (nunique)\n\t- Unique Value Percentage\n\n\tReturns\n\t-------\n\tpandas.core.frame.DataFrame\n\t\"\"\"\n\n\tdf_cols = pd.DataFrame(self._obj.columns.tolist())\n\tdf_cols = df_cols.reset_index()\n\tdf_cols.columns = ['ColIndex', 'Col_Name']\n\treport_missing = self.isnull_list()\n\tdf_cols = df_cols.merge(report_missing, 'left', 'Col_Name')\n\n\treport_nunique = self.nunique()\n\tdf_cols = df_cols.merge(report_nunique, 'left', 'Col_Name')\n\n\treport_type = pd.DataFrame(self._obj.dtypes).reset_index()\n\treport_type.columns = ['Col_Name', 'Data_Type']\n\treport_type.Data_Type = report_type.Data_Type.map(lambda x: str(x))\n\tdf_cols = df_cols.merge(report_type, 'left', 'Col_Name')\n\treturn df_cols\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.interactive","title":"<code>interactive()</code>  <code>staticmethod</code>","text":"<p>Set InteractiveShell.ast_node_interactivity = \"all\" Set mpl.use(\"module://backend_interagg\") Set plt.ion()</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>@staticmethod\ndef interactive():\n\"\"\"\n\tSet InteractiveShell.ast_node_interactivity = \"all\"\n\tSet mpl.use(\"module://backend_interagg\")\n\tSet plt.ion()\n\n\t\"\"\"\n\tfrom IPython.core.interactiveshell import InteractiveShell\n\tInteractiveShell.ast_node_interactivity = \"all\"\n\tmpl.use(\"module://backend_interagg\")\n\tplt.ion()\n\tprint(\"Package loaded in Non-Notebook Mode | mpl.use('module://backend_interagg') | plt.ion()\" )\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.isnull","title":"<code>isnull(colname)</code>","text":"<p>Count the rows (and the %) of missing values in the specified column</p>"},{"location":"reference/#dsx.ds_utils.dsx.isnull--parameters","title":"Parameters","text":"str <p>Single column name</p>"},{"location":"reference/#dsx.ds_utils.dsx.isnull--returns","title":"Returns","text":"<p>(Count of Missing Rows, Percentage of Missing Rows): tuple</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def isnull(self, colname: str) -&gt; tuple:\n\"\"\"\n\tCount the rows (and the %) of missing values in the specified column\n\n\tParameters\n\t----------\n\tcolname: str\n\t\tSingle column name\n\n\tReturns\n\t-------\n\t(Count of Missing Rows, Percentage of Missing Rows): tuple\n\t\"\"\"\n\n\tdf = self._obj\n\ttemp = df[df[colname].isnull()]\n\treturn (len(temp), len(temp) / len(df))\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.isnull_list","title":"<code>isnull_list(col_names_list=None)</code>","text":"<p>Generate a report of cases with missing values</p>"},{"location":"reference/#dsx.ds_utils.dsx.isnull_list--parameters","title":"Parameters","text":"list, optional <p>List of columns to be included in the report. If not specified, all columns will be used.</p>"},{"location":"reference/#dsx.ds_utils.dsx.isnull_list--returns","title":"Returns","text":"<p>pandas.core.frame.DataFrame</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def isnull_list(self, col_names_list=None) -&gt; pd.core.frame.DataFrame:\n\"\"\"\n\tGenerate a report of cases with missing values\n\n\tParameters\n\t----------\n\tcol_names_list: list, optional\n\t\tList of columns to be included in the report.\n\t\tIf not specified, all columns will be used.\n\n\n\tReturns\n\t-------\n\tpandas.core.frame.DataFrame\n\t\"\"\"\n\tdataframe_df = self._obj\n\tif type(dataframe_df) != pd.core.frame.DataFrame:\n\t\tprint('The method requires Pandas DataFrame as the input')\n\t\treturn\n\telse:\n\t\tif col_names_list == None:\n\t\t\tcol_names_list = dataframe_df.columns.tolist()\n\t\tif not isinstance(col_names_list, list):\n\t\t\tcol_names_list = [col_names_list]\n\n\t\tif len(col_names_list) &gt; 0:\n\t\t\tfetcher = []\n\t\t\tfor col in col_names_list:\n\t\t\t\ttupx = self.isnull(col)\n\t\t\t\tfetcher.append({'Col_Name': col, 'Missing_Count': tupx[0], 'Missing_Percentage': tupx[1]})\n\t\t\tfetcher = pd.DataFrame(fetcher)\n\t\t\treturn fetcher\n\t\telse:\n\t\t\tprint('There is no item in the columns')\n\t\t\treturn None\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.matplotlib_config","title":"<code>matplotlib_config()</code>  <code>staticmethod</code>","text":"<p>Print matplotlib configurations</p>"},{"location":"reference/#dsx.ds_utils.dsx.matplotlib_config--returns","title":"Returns","text":"<p>lines of texts: str</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>@staticmethod\ndef matplotlib_config():\n\"\"\"\n\tPrint matplotlib configurations\n\n\tReturns\n\t-------\n\tlines of texts: str\n\n\t\"\"\"\n\tprint('%matplotlib inline')\n\tprint(\"%config InlineBackend.figure_format = 'retina'\")\n\tprint(\"sns.set_style('fivethirtyeight')\")\n\tprint(\"plt.rc('figure', figsize=(16,9))\")\n\tprint(\"sns.set_context(context={'figure.figsize': (16,9)})\")\n\tprint(\"plt.style.use('fivethirtyeight')\")\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.nunique","title":"<code>nunique(col_names_list=None)</code>","text":"To generate <p>1) the number of unique values 2) the percentage of the unique value over the total records (or rows)</p>"},{"location":"reference/#dsx.ds_utils.dsx.nunique--parameters","title":"Parameters","text":"list <p>If not specified, all column names will be used</p>"},{"location":"reference/#dsx.ds_utils.dsx.nunique--returns","title":"Returns","text":"<p>pd.core.frame.DataFrame</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def nunique(self, col_names_list=None) -&gt; pd.core.frame.DataFrame:\n\"\"\"\n\tTo generate:\n\t\t1) the number of unique values\n\t\t2) the percentage of the unique value over the total records (or rows)\n\n\tParameters\n\t----------\n\tcol_names_list: list\n\t\tIf not specified, all column names will be used\n\n\tReturns\n\t-------\n\tpd.core.frame.DataFrame\n\t\"\"\"\n\tdf_input = self._obj\n\tif col_names_list is None:\n\t\tcol_names_list = df_input.columns.tolist()\n\tif len(col_names_list) &gt; 0:\n\t\tfetcher = []\n\t\tfor col in col_names_list:\n\t\t\tn = df_input[col].nunique()\n\t\t\tfetcher.append({'Col_Name': col, 'Unique_Values': n})\n\t\tfetcher = pd.DataFrame(fetcher)\n\t\tfetcher['Prcent_Unique_Values'] = fetcher.Unique_Values.map(lambda x: x / len(df_input))\n\t\treturn fetcher\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.plt_labels","title":"<code>plt_labels(percent=False, fontsize=None, color=None, denominator=None)</code>  <code>staticmethod</code>","text":"<p>To insert label for each element in the current axes (last chart created). Parameters</p> <p>percent: bool fontsize: float color: str denominator: float</p>"},{"location":"reference/#dsx.ds_utils.dsx.plt_labels--returns","title":"Returns","text":"<p>None</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>@staticmethod\ndef plt_labels(percent=False, fontsize=None, color=None, denominator=None):\n\"\"\"\n\tTo insert label for each element in the current axes (last chart created).\n\tParameters\n\t----------\n\tpercent: bool\n\tfontsize: float\n\tcolor: str\n\tdenominator: float\n\n\tReturns\n\t-------\n\tNone\n\t\"\"\"\n\tax = plt.gca()\n\tfor p in ax.patches:\n\t\tif percent:\n\t\t\tax.text(p.get_x() + (p.get_width() / 2), p.get_height(), round(p.get_height() / denominator * 100, 1),\n\t\t\t        ha='center', va='bottom')\n\t\telse:\n\t\t\tax.text(p.get_x() + (p.get_width() / 2), p.get_height(), p.get_height(), ha='center', va='bottom')\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.rename","title":"<code>rename(col_index_or_name, col_name_new, inplace=True)</code>","text":"<p>To rename single column Parameters</p> <p>col_index_or_name col_name_new inplace</p>"},{"location":"reference/#dsx.ds_utils.dsx.rename--returns","title":"Returns","text":"pd.core.frame.DataFrame <p>Only if inplace is set to False.</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def rename(self, col_index_or_name:Union[str, int], col_name_new, inplace:bool=True):\n\"\"\"\n\tTo rename single column\n\tParameters\n\t----------\n\tcol_index_or_name\n\tcol_name_new\n\tinplace\n\n\tReturns\n\t-------\n\trenamed_DataFrame: pd.core.frame.DataFrame\n\t\tOnly if inplace is set to False.\n\t\"\"\"\n\tdf_input = self._obj\n\tif inplace:\n\t\tdf = df_input\n\telse:\n\t\tdf = df_input.copy()\n\n\tif str(col_index_or_name).isnumeric() == True:\n\t\tcolName_Old = df.columns.tolist()[col_index_or_name]\n\telse:\n\t\tcolName_Old = col_index_or_name\n\n\tif colName_Old in [col for col in df.columns.tolist()]:\n\t\tdf.rename(columns={colName_Old: col_name_new}, inplace=True)\n\telse:\n\t\tprint(\"Error: The \" + colName_Old + \" is not an existing column name.\")\n\n\tif inplace:\n\t\tdf_input = df.copy()\n\telse:\n\t\treturn df\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.reset_index","title":"<code>reset_index(index_label='RID', inplace=True)</code>","text":"<p>To reset index and immediately rename the old 'index' to new index_label defined.</p>"},{"location":"reference/#dsx.ds_utils.dsx.reset_index--parameters","title":"Parameters","text":"<p>index_label: str, optional</p> <p>inplace: bool, optional</p>"},{"location":"reference/#dsx.ds_utils.dsx.reset_index--returns","title":"Returns","text":"<p>pd.core.frame.DataFrame         ONLY when inplace == False</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def reset_index(self, index_label:str=\"RID\", inplace:bool=True):\n\"\"\"\n\tTo reset index and immediately rename the old 'index' to new index_label defined.\n\n\tParameters\n\t----------\n\tindex_label: str, optional\n\n\tinplace: bool, optional\n\n\tReturns\n\t-------\n\tpd.core.frame.DataFrame\n\t\tONLY when inplace == False\n\t\"\"\"\n\n\tdf_input = self._obj\n\tif inplace:\n\t\tdf = df_input\n\telse:\n\t\tdf = df_input.copy()\n\n\tdf.reset_index(inplace=True)\n\tdf.ds.rename('index', index_label)\n\n\tif inplace:\n\t\tdf_input = df.copy()\n\telse:\n\t\treturn df\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.set_dirs","title":"<code>set_dirs(root=False)</code>  <code>classmethod</code>","text":"<p>Set the project root folder.</p>"},{"location":"reference/#dsx.ds_utils.dsx.set_dirs--parameters","title":"Parameters","text":"bool, optional <p>To indicate whether the current active directory is the root or sub-directory of the project</p>"},{"location":"reference/#dsx.ds_utils.dsx.set_dirs--returns","title":"Returns","text":"<p>None</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>@classmethod\ndef set_dirs(cls, root=False):\n\"\"\"\n\tSet the project root folder.\n\n\tParameters\n\t----------\n\troot: bool, optional\n\t\tTo indicate whether the current active directory is the root or sub-directory of the project\n\n\tReturns\n\t-------\n\tNone\n\t\"\"\"\n\n\tdir = None\n\tif root:\n\t\tdir = os.getcwd()\n\telse:\n\t\tdir = os.path.join(os.getcwd(), \"..\")\n\tos.chdir(dir)\n\n\tcls.dir_project = os.getcwd()\n\tcls.dir_data = os.path.join(cls.dir_project, 'data')\n\tcls.dir_temp = os.path.join(cls.dir_project, '_temp')\n\n\tprint('Set project directory to {}.'.format(os.getcwd()))\n\tprint('Property \"dir_%\" enabled')\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.set_ipython","title":"<code>set_ipython(node_interactivity='last')</code>  <code>staticmethod</code>","text":"<p>Set ast_node_interactivity in Ipython.core.InteractiveShell</p>"},{"location":"reference/#dsx.ds_utils.dsx.set_ipython--parameters","title":"Parameters","text":"str, optional <p>Default is 'last'. DSX uses 'all' if kernel is detected.</p>"},{"location":"reference/#dsx.ds_utils.dsx.set_ipython--returns","title":"Returns","text":"<p>None</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>@staticmethod\ndef set_ipython(node_interactivity:str='last'):\n\"\"\"\n\tSet ast_node_interactivity in Ipython.core.InteractiveShell\n\n\tParameters\n\t----------\n\tnode_interactivity: str, optional\n\t\tDefault is 'last'. DSX uses 'all' if kernel is detected.\n\n\tReturns\n\t---\n\tNone\n\n\t\"\"\"\n\tfrom IPython.core.interactiveshell import InteractiveShell\n\tInteractiveShell.ast_node_interactivity = node_interactivity\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.setup_project","title":"<code>setup_project(root=True, get_xfiles=False, xfiles_url=None, git_files=False)</code>  <code>classmethod</code>","text":"<p>Setup project directories for new projects. If the directories exist, will not be overwritten.</p>"},{"location":"reference/#dsx.ds_utils.dsx.setup_project--parameters","title":"Parameters","text":"<p>root: bool, optional get_xfiles: bool, optional git_files: bool, optional</p>"},{"location":"reference/#dsx.ds_utils.dsx.setup_project--returns","title":"Returns","text":"<p>None</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>@classmethod\ndef setup_project(cls, root=True, get_xfiles=False, xfiles_url=None, git_files=False):\n\"\"\"\n\tSetup project directories for new projects.\n\tIf the directories exist, will not be overwritten.\n\n\tParameters\n\t----------\n\troot: bool, optional\n\tget_xfiles: bool, optional\n\tgit_files: bool, optional\n\n\tReturns\n\t-------\n\tNone\n\t\"\"\"\n\t#cls.set_dirs(root=root)\n\tcls.dir_project = os.getcwd()\n\tcls.dir_data = os.path.join(cls.dir_project, 'data')\n\tcls.dir_temp = os.path.join(cls.dir_project, '_temp')\n\n\tfolders = ['data', 'data/temp', 'data/inputs', 'data/outputs', 'notebooks', '_temp']\n\tfor folder in folders:\n\t\tif os.path.exists(os.path.join(cls.dir_project, folder)) == False:\n\t\t\tos.mkdir(os.path.join(cls.dir_project, folder))\n\tprint('Created project structure')\n\n\n\tif get_xfiles:\n\t\tos.mkdir(os.path.join(cls.dir_project, '_temp'))\n\n\t\tos.chdir(cls.dir_temp)\n\t\tif not os.path.exists('xbase.html'):\n\t\t\timport urllib\n\t\t\turllib.request.urlretrieve(xfiles_url, 'xbase.html')\n\n\n\t\tos.chdir(cls.dir_project)\n\t\tprint('Downloaded Extra Files.')\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.split","title":"<code>split(col, sep, index_label='RID', drop_innerindex=True, reset_index_inplace=True)</code>","text":"<p>To generate a DataFrame by splitting the values in a string, where the values are separated by a separator character.</p> <p>This method is improved upon the original split method in pandas. Where there is no separator in a row, the value will still be posted to the newly generated DataFrame as the outputs.</p>"},{"location":"reference/#dsx.ds_utils.dsx.split--parameters","title":"Parameters","text":"<p>col: str sep: str index_label: str drop_innerindex: bool reset_index_inplace</p>"},{"location":"reference/#dsx.ds_utils.dsx.split--returns","title":"Returns","text":"<p>pd.core.frame.DataFrame</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def split(self, col:str, sep:str, index_label:str='RID',\n                                             drop_innerindex:bool=True, reset_index_inplace:bool=True):\n\"\"\"\n\tTo generate a DataFrame by splitting the values in a string, where the values are separated by a separator\n\tcharacter.\n\n\tThis method is improved upon the original split method in pandas. Where there is no separator in a row,\n\tthe value will still be posted to the newly generated DataFrame as the outputs.\n\n\tParameters\n\t----------\n\tcol: str\n\tsep: str\n\tindex_label: str\n\tdrop_innerindex: bool\n\treset_index_inplace\n\n\tReturns\n\t-------\n\tpd.core.frame.DataFrame\n\t\"\"\"\n\tif reset_index_inplace:\n\t\tdfo = self._obj\n\telse:\n\t\tdfo = self._obj.copy()\n\tdfo.reset_index(drop=True, inplace=True)\n\tdfo.ds.reset_index(index_label=index_label)\n\n\tdf = dfo.copy()\n\tdf[col + \"_splitready\"] = df[col].map(lambda x: str(x) + sep if sep not in str(x) else str(x))\n\tdf = df[[index_label, col + \"_splitready\"]].copy()\n\tdf.set_index(index_label, inplace=True)\n\tdf = df[col + \"_splitready\"].str.split(sep, expand=True).stack().reset_index()\n\tdf.columns = [index_label, 'InnerIndex', col]\n\n\tdf[col] = df[col].str.replace(sep, '')\n\tdf[col] = df[col].replace('', np.nan)\n\tdf.dropna(subset=[col], inplace=True)\n\n\tdf[col] = df[col].str.strip()\n\n\tif drop_innerindex:\n\t\tdf.drop('InnerIndex', 'columns', inplace=True)\n\n\treturn df\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.to_dict","title":"<code>to_dict(key_col, val_col)</code>","text":"<p>To generate dictionary from two columns Parameters</p> <p>key_col: str val_col: str</p>"},{"location":"reference/#dsx.ds_utils.dsx.to_dict--returns","title":"Returns","text":"<p>pd.core.frame.DataFrame</p> Source code in <code>dsx/ds_utils.py</code> <pre><code>def to_dict(self, key_col:str, val_col:str) -&gt; pd.core.frame.DataFrame:\n\"\"\"\n\tTo generate dictionary from two columns\n\tParameters\n\t----------\n\tkey_col: str\n\tval_col: str\n\n\tReturns\n\t-------\n\tpd.core.frame.DataFrame\n\t\"\"\"\n\tdf = self._obj\n\tdict = {}\n\tfor index, row in df.iterrows():\n\t\tdict[row[key_col]] = row[val_col]\n\treturn dict\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.to_excel_stringify","title":"<code>to_excel_stringify(dir=None, strings_to_urls_bool=False)</code>","text":"<p>Faster option to export Excel File, with the option to stringify all hyperlinks in the table. Parameters</p> <p>dir strings_to_urls_bool</p>"},{"location":"reference/#dsx.ds_utils.dsx.to_excel_stringify--returns","title":"Returns","text":"Source code in <code>dsx/ds_utils.py</code> <pre><code>def to_excel_stringify(self, dir=None, strings_to_urls_bool=False):\n\"\"\"\n\tFaster option to export Excel File, with the option to stringify all hyperlinks in the table.\n\tParameters\n\t----------\n\tdir\n\tstrings_to_urls_bool\n\n\tReturns\n\t-------\n\n\t\"\"\"\n\tif dir is None:\n\t\tdir = self.dir_data\n\n\twriter = pd.ExcelWriter(dir, engine='xlsxwriter', options={'strings_to_urls': strings_to_urls_bool})\n\tself._obj.to_excel(writer)\n\twriter.close()\n\tprint(\"Exported Excel File to \" + dir)\n</code></pre>"},{"location":"reference/#dsx.ds_utils.dsx.xv","title":"<code>xv(title=None, convert_time=True, width='100%', height='1200', dirhtml='../_temp', dirbase='_temp', **kwargs)</code>","text":""},{"location":"reference/#dsx.ds_utils.dsx.xv--parameters","title":"Parameters","text":"<p>title: str, Title for the new viewer file.</p> <p>convert: bool, Convert datetime dtype to str for display.</p>"},{"location":"reference/#dsx.ds_utils.dsx.xv--returns","title":"Returns","text":"Source code in <code>dsx/ds_utils.py</code> <pre><code>def xv(self, title=None, convert_time=True, width=\"100%\", height=\"1200\", dirhtml=\"../_temp\", dirbase=\"_temp\", **kwargs):\n\"\"\"\n\n\tParameters\n\t----------\n\ttitle: str, Title for the new viewer file.\n\n\tconvert: bool, Convert datetime dtype to str for display.\n\n\n\tReturns\n\t-------\n\n\t\"\"\"\n\tfrom IPython.display import IFrame\n\tviewer_filename = self._obj.ds.to_xv(title, convert_time=convert_time, dirbase=dirbase)\n\treturn IFrame(os.path.join(dirbase, (viewer_filename+'.html')), width=width, height=height)\n</code></pre>"}]}